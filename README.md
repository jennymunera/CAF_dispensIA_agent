# CAF_dispensIA_agent

Este repositorio contiene un Ãºnico **Azure Function App** llamado `azfunc-MVP-DispensAI` que expone tres funciones (`router`, `dispensas_process` y `csv_global`). Cada handler se registra en `function_app.py` mediante el programming model v2 de Azure Functions, actuando como controller: recibe el trigger, valida parÃ¡metros obligatorios (mensajes en espaÃ±ol) y delega en servicios especializados ubicados en `src/`.

> **Modelo v2**: no se crean carpetas individuales con `__init__.py` ni `function.json`. Los decoradores `@app.service_bus_queue_trigger`, `@app.route`, etc., generan la configuraciÃ³n automÃ¡ticamente en tiempo de ejecuciÃ³n.

## Ãrbol del proyecto con descripciones
```
azfunc-MVP-DispensAI/
â”œâ”€â”€ .funcignore                  # Exclusiones para despliegues de Azure Functions
â”œâ”€â”€ .gitignore                   # Archivos y carpetas ignorados por Git
â”œâ”€â”€ README.md                    # Documento de contexto, arquitectura y plan de trabajo
â”œâ”€â”€ function_app.py              # Punto de entrada; registra handlers y compone servicios
â”œâ”€â”€ host.json                    # ConfiguraciÃ³n global del Function App
â”œâ”€â”€ local.settings.json          # Variables de entorno para desarrollo local
â”œâ”€â”€ requirements.txt             # Dependencias de Python del Function App
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ interfaces/
â”‚   â”‚   â””â”€â”€ blob_storage_interface.py    # Contrato abstracto para operaciones contra Blob Storage
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ dispensa_task.py             # Modelo/validador para tareas individuales de procesamiento
â”‚   â”‚   â””â”€â”€ queue_message.py             # Modelo/validador de mensajes de la cola inicial
â”‚   â”œâ”€â”€ prompts/                         # Plantillas y prompts (pendiente de poblar)
â”‚   â”œâ”€â”€ repositories/
â”‚   â”‚   â””â”€â”€ blob_storage_repository.py   # ImplementaciÃ³n del repositorio de blobs con Azure SDK
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ blob_dispatcher.py           # Genera tareas por documento segÃºn la solicitud del router
â”‚   â”‚   â”œâ”€â”€ dispensas_processor.py       # Orquesta el flujo OpenAI para cada documento
â”‚   â”‚   â”œâ”€â”€ notifications_service.py     # Servicio existente para notificaciones externas
â”‚   â”‚   â”œâ”€â”€ openai_chained_service.py    # Encapsula la llamada de respuesta encadenada a OpenAI
â”‚   â”‚   â”œâ”€â”€ openai_client_factory.py     # Centraliza la autenticaciÃ³n y creaciÃ³n del cliente OpenAI
â”‚   â”‚   â”œâ”€â”€ openai_file_service.py       # Gestiona solicitudes con archivo (subida a OpenAI)
â”‚   â”‚   â”œâ”€â”€ openai_http_client.py        # Cliente HTTP que invoca las funciones internas de OpenAI
â”‚   â”‚   â””â”€â”€ service_bus_dispatcher.py    # EnvÃ­a mensajes de tareas a Service Bus
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ blob_url_parser.py           # Extrae contenedor y nombre de blob a partir de la URL
â”‚       â”œâ”€â”€ build_email_payload.py       # Utilidad previa para payloads de notificaciÃ³n
â”‚       â”œâ”€â”€ content_type.py              # Define filename y content-type basados en la extensiÃ³n
â”‚       â”œâ”€â”€ prompt_loader.py             # Lee prompts desde archivos ubicados en `src/prompts`
â”‚       â””â”€â”€ response_parser.py           # Extrae texto de respuestas OpenAI y convierte a JSON
â””â”€â”€ .vscode/
    â””â”€â”€ settings.json            # ConfiguraciÃ³n del editor (VS Code)
```

## Detalle de la arquitectura
- **`function_app.py`**: capa de controllers. AllÃ­ se resuelven variables de entorno, se instancian repositorios/servicios y se definen los handlers HTTP y Service Bus. Los endpoints HTTP `request-with-file` y `chained-request` reutilizan la lÃ³gica de OpenAI y son consumidos internamente por `dispensas_process`.
- **Modelos (`src/models/`)**: encapsulan y validan los datos de entrada.
  - `QueueMessageModel` normaliza el mensaje de Service Bus inicial (proyecto, tipo de disparo, documentos, prompts, modelo).
  - `DispensaTaskModel` representa la tarea a nivel de documento que consumirÃ¡ la funciÃ³n `dispensas_process`.
- **Interfaces y repositorios**: `BlobStorageInterface` define el contrato para trabajar con blobs y `BlobStorageRepository` implementa la lÃ³gica con `BlobServiceClient`, incluyendo subir texto/bytes, descargar y listar blobs con logs en espaÃ±ol.
- **Servicios OpenAI**: `OpenAIClientFactory` abstrae la autenticaciÃ³n (API Key o Azure AD). `OpenAIFileService` porta la lÃ³gica de `request_with_file` (descargar blob, subir a OpenAI, obtener respuesta). `OpenAIChainedService` encapsula `previous_response_id` para continuar la conversaciÃ³n. `OpenAIHttpClient` llama a los endpoints HTTP internos. `DispensasProcessorService` usa este cliente HTTP para orquestar el flujo de respuestas. `BlobDispatcherService` fan-out de tareas segÃºn proyecto/documento. `notifications_service.py` permanece como servicio auxiliar preexistente.
- **Utilidades (`src/utils/`)**: funciones de apoyo reutilizables (parseo de URL de blob, determinaciÃ³n de content-type, extracciÃ³n de texto/JSON de OpenAI, payloads de email).
- **Utilidades (`src/utils/`)**: funciones de apoyo reutilizables (parseo de URL de blob, determinaciÃ³n de content-type, extracciÃ³n de texto/JSON de OpenAI, lectura de prompts desde archivos, payloads de email).

## Flujo de las funciones
1. **Router (`ServiceBusQueueTrigger`)**
   - Recibe un mensaje con `project_id`, `trigger_type`, documentos opcionales, modelo y prompts.
   - Se valida con `QueueMessageModel` (mensajes de error en espaÃ±ol).
   - `BlobDispatcherService` determina quÃ© blobs procesar: todos los del proyecto (`trigger_type = project`) o los documentos especÃ­ficos (`trigger_type = document`).
   - Por cada blob genera una tarea (`DispensaTaskModel`) y la envÃ­a a la cola de trabajo que activarÃ¡ `dispensas_process`.

2. **Dispensas Process (`ServiceBusQueueTrigger`)**
   - Consume cada `DispensaTaskModel` de la cola.
   - `DispensasProcessorService` llama a los endpoints HTTP internos:
     1. `request-with-file`: prepara el archivo, lo sube a OpenAI y devuelve la respuesta inicial.
     2. `chained-request`: reutiliza el `response_id` anterior para obtener la respuesta encadenada.
     3. Convierte el contenido retornado a JSON (`response_parser.parse_json_response`).
   - Devuelve un diccionario con metadatos del documento, respuestas raw y JSON parseado listo para persistir o publicar.

   Los documentos de entrada por proyecto residen en `https://samvpdispensiacr.blob.core.windows.net/dispensia-documents/basedocuments/{project}/raw/` y las respuestas en JSON se deben almacenar en `https://samvpdispensiacr.blob.core.windows.net/dispensia-documents/basedocuments/{project}/results/`.

3. **CSV Global (`HTTP Trigger`, pendiente)**
   - ConsolidarÃ¡ las respuestas generadas en un CSV fila a fila. Se implementarÃ¡ despuÃ©s de validar las dos funciones anteriores.

## Plan de trabajo
1. **Definir modelos** âœ… â€” `QueueMessageModel` y `DispensaTaskModel` creados.
2. **Servicios auxiliares** âœ… â€” `OpenAIClientFactory`, `OpenAIFileService`, `OpenAIChainedService`, `DispensasProcessorService`, `BlobDispatcherService`, `ServiceBusDispatcher` ya implementados.
3. **Repositorios/utilidades** âœ… â€” `BlobStorageRepository` extendido y helpers (`blob_url_parser`, `content_type`, `response_parser`) aÃ±adidos.
4. **Actualizar `function_app.py`** âœ… â€” Handlers `router` y `dispensas_process` configurados; `csv_global` se implementarÃ¡ mÃ¡s adelante.
5. **Configurar dependencias** ğŸ”„ â€” `requirements.txt` actualizado con `azure-identity`, `azure-servicebus`, `openai`, `requests`; pendiente documentar ajustes finales en `local.settings.json` si cambian variables.
6. **Pruebas iniciales** â€” Simular mensajes de Service Bus con `azure-functions-core-tools`, validar logs, manejo de errores y resultados.

### Estado actual de las funciones 1 y 2
- **Handlers listos**: `router` y `dispensas_process` ya existen en `function_app.py` y delegan en los servicios correspondientes.
- **Endpoints HTTP**: `request-with-file` y `chained-request` expuestos como API reutilizando la lÃ³gica de OpenAI; `dispensas_process` los invoca mediante `OpenAIHttpClient`.
- **Servicios y utilidades portados**: flujo `request_with_file` y `chained_request` encapsulado en `openai_file_service.py` y `openai_chained_service.py`; fan-out y publicaciÃ³n en Service Bus resuelto con `blob_dispatcher.py` y `service_bus_dispatcher.py`.
- **Pendiente**:
  - Actualizar `local.settings.json` (o variables de aplicaciÃ³n) con `SERVICE_BUS_CONNECTION`, `ROUTER_QUEUE_NAME`, `PROCESS_QUEUE_NAME`, `DEFAULT_OPENAI_MODEL`, `DEFAULT_AGENT_PROMPT`, `DEFAULT_CHAINED_PROMPT` y credenciales de Blob/OpenAI.
  - Instalar dependencias (`pip install -r requirements.txt`).
  - Ejecutar pruebas locales: enviar un mensaje de ejemplo a `dispensas-router-in`, verificar generaciÃ³n de tareas y procesamiento completo, ajustar logging y manejo de errores segÃºn sea necesario.

## Variables de entorno claves
- `AZURE_STORAGE_CONNECTION_STRING`, `DEFAULT_BLOB_CONTAINER`: acceso a Blob Storage.
- `AZURE_OPENAI_ENDPOINT`, `USE_API_KEY`, `AZURE_OPENAI_API_KEY`: autenticaciÃ³n contra Azure OpenAI.
- `SERVICE_BUS_CONNECTION`: cadena de conexiÃ³n con permisos para enviar y recibir en las colas.
- `ROUTER_QUEUE_NAME`, `PROCESS_QUEUE_NAME`: nombres de las colas (por defecto `dispensas-router-in` y `dispensas-process-in`).
- `DEFAULT_OPENAI_MODEL`, `DEFAULT_AGENT_PROMPT`, `DEFAULT_CHAINED_PROMPT`: valores por defecto utilizados cuando el mensaje de la cola no los especifica.
- `DEFAULT_AGENT_PROMPT_FILE`, `DEFAULT_CHAINED_PROMPT_FILE`: nombres de archivos (relativos a `src/prompts/`) desde los que se cargarÃ¡n los prompts; si se omiten, se usan los valores inline anteriores como fallback.
- `INTERNAL_API_BASE_URL`: URL base del Function App para invocar los endpoints HTTP internos (por defecto `http://127.0.0.1:7071/api` en local).
- `INTERNAL_API_KEY`: clave opcional (`x-functions-key`) si los endpoints HTTP requieren autenticaciÃ³n (`FUNCTION` o `ADMIN`).

## Referencia cruzada
- Proyecto base: `/Users/jenny/Downloads/openai_responses_function_app`. De allÃ­ se portaron las funcionalidades `request_with_file` y `chained_request`, hoy encapsuladas en `openai_file_service.py` y `openai_chained_service.py`.

Este README se actualizarÃ¡ conforme se implementen los handlers y la funciÃ³n `csv_global`.
